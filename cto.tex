\section{On the Edge Computing}

Conventional visual monitoring systems, CCTV, IP cameras, send video transmission, analog or digital, to a data center to be stored and eventually processed or reviewed. Embedded smart cameras process image data directly on-site allowing several advantages over the last systems, in this paper we present:

\begin{itemize}[noitemsep] % [noitemsep] removes whitespace between the items for a compact look
\item \textit{Our approach} to an on-board smart camera computing device.
\item \textit{Hardware and Software description}.
\item \textit{Actual real Use Case implementation} of our product. 
\end{itemize}


Nevertheless, there is a strong demand for mobile vision solutions ranging from object recognition to advanced human-machine interfaces.

\subsection{Our Approach}

The problem of on-board computing and further analysis of real time video is subject of current research. We follow the next procedure which is focused on 3 main cycles that are plot in figure \ref{fig:cycle} and are stated as follows:

\begin{figure}[h]\centering
	\includegraphics[width=0.6\linewidth]{images/cycle}
	\caption{Cycle of work}
	\label{fig:cycle}
\end{figure}

% Explain the DEMS cicle for target project
\begin{itemize}

\item[1] \textit{Algorithm Design}. If the client requirements does not have precedents, we partially hand craft a Computer Vision Algorithm specific for our client use case for data mining, cleaning and analysis.
\item[2] Data Analysis for client use cases and results presentation according to initial requirements.
\item[3] \textit{Improvement}. Improve original algorithm using the proprietary collected data with the use of Machine Learning techniques, together with a hardware upgrade if required.
     
\end{itemize}

We dedicate a specialized team to solve the problems in each cycle. The case study that we present in the whole proposal, completed 2 of the 3 states of our cycle of work, and we are currently working on an improvement of our main hardware and algorithm to provide the best results to our clients. The collected data is a huge advantage above other competitors and allows us to improve existing products and create new ones.

\subsection{Hardware and Software description}
Below there is a description of the hardware and software we use.

\subsubsection{Software Description}
If the requirements are very specific and no historic data is available, we design an algorithm with traditional computer vision techniques according to the use case with focus on the embedded hardware; we maintain a constant monitoring of the program for the event that client is looking for and at the same time we collect data for three main purposes: Improve the current algorithm with Machine Learning techniques; Bring data for further applications; Create new useful labeled data in the field of work.

Our main tools for the creation of custom algorithms are Python and C++ as main languages. Open-CV is our compendium of multiple purpose Computer Vision techniques which are used to hand craft the desired behavior of the program and data recollection.

\subsubsection{Hardware Description}

The figure \ref{fig:hardware_dec} shows some main aspects of our smart-camera and contains:
\begin{itemize}
	\item A low resolution camera, used to detect flow in real time.
	\item A 8 MP camera sensor is used for capture the main aspects of interest when the low resolution camera triggers the signal of event of interest, in real time.
	\item We also develop custom printed circuit boards to handle different sensors or actuators like the infra-red filter switch for night vision improvements. Custom boards can include several sensors or actuators like GPS, GSM and others 
\end{itemize} 

\begin{figure}[b]\centering
	\includegraphics[width=\linewidth]{images/hardware_desc}
	\caption{Hardware schematics}
	\label{fig:hardware_dec}
\end{figure}

The compute capabilities of our embedded device are described below:

\begin{itemize}[noitemsep]

\item SoC: Broadcom BCM2837B0 quad-core A53 (ARMv8) 64-bit @ 1.4GHz
\item GPU: Broadcom Videocore-IV 256 MB VRAM
\item RAM: 1GB LPDDR2 SDRAM
\item Networking: Gigabit Ethernet.
\item 802.11b/g/n/ac Wi-Fi
\item Bluetooth: Bluetooth 4.2, Bluetooth Low Energy (BLE)
\item Storage: Micro-SD
\item Multiple GPIO header
\item Ports: HDMI, analogue audio-video jack, USB 2.0, Ethernet
\item Camera Serial Interface (CSI), Display Serial Interface (DSI)
\item Optional - Neural Network Compute Capabilities according to use case.
\end{itemize}


\subsection{Actual real Use Case implementation}

In figure \ref{fig:work_dec} we present an implementation schematics of our camera.

\begin{figure}[t]\centering
	\includegraphics[width=\linewidth]{images/lucam}
	\caption{Actual use case of our embedded camera}
	\label{fig:work_dec}
\end{figure}

\begin{itemize}[noitemsep] % [noitemsep] removes whitespace between the items for a

\item[1]- On Board Computation according to client requirements, communication to a private cloud can be achieved if required.
\item[2]- Mounting pole, in some applications the height of the device plays an important role in the algorithm behavior.
\item[3-8]- Specific working environment, in this case for traffic infringements detection.
\item[4]- Optimal vision angle for plate detection.
\item[5]- Target object, in this case, cars.
\item[6]- Traffic light mounting pole,
\item[7]- Traffic Light signal. The camera is capable of detecting color change if the traffic light is within it's range of optimal working, it is implemented by software but can be implemented as hardware if the client requires.
\end{itemize}
Figure \ref{fig:sync} shows the extract of 5 seconds video from low resolution camera and a picture of High Resolution for target object with region of interest, this two assets, video and picture is the output of our custom algorithm in real time.

As stated before, if an Internet connection is available, we can make a wingspan of the information of video/picture in real time and serve it to different users as required, or save it in a server for further analysis, figure \ref{fig:online} shows the camera and system online behavior.


\begin{figure}[t]\centering
	\includegraphics[width=\linewidth]{images/online}
	\caption{On-line process for the information detected in the road. }
	\label{fig:online}
\end{figure}

Currently we are training a Neural Network Algorithm to support the Hand Crafted algorithm with the information of video and image generated from the beginning of this year 2018. Following our cycle of work of Figure \ref{fig:work_dec}, we have generated enough labeled data for our use case and we are ready to start a new cycle of production.

You can see the partial results of this project in our page \href{www.demsbo.com}{www.demsbo.com} and our Github project \href{https://github.com/alvarohurtadobo/prototipo}{https://github.com/alvarohurtadobo/prototipo}.

